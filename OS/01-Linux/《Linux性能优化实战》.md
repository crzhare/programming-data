# [《Linux性能优化实战》](https://time.geekbang.org/column/intro/140) 主要知识点整理

---

## 1 如何学习 Linux 性能优化

性能问题并没有你想像得那么难，只要你理解了应用程序和系统的少数几个基本原理，再进行大量的实战练习，建立起整体性能的全局观，大多数性能问题的优化就会水到渠成。

1. 性能指标：
   1. 从应用负载的视角来考察性能：“高并发”和“响应快”，对应着性能优化的两个核心指标——“吞吐”和“延时”。
   2. 从系统资源的视角出发的指标：与“吞吐”和“延时”对应，有资源使用率、饱和度等。
2. 解决性能问题的本质：
   1. 性能问题的本质：系统资源已经达到瓶颈，但请求的处理却还不够快，无法支撑更多的请求。
   2. 性能分析：找出应用或系统的瓶颈，并设法去避免或者缓解它们，从而更高效地利用系统资源处理更多的请求。
3. 性能分析的步骤：
   1. 选择指标评估应用程序和系统的性能；
   2. 为应用程序和系统设置性能目标；
   3. 进行性能基准测试；
   4. 性能分析定位瓶颈；
   5. 优化系统和应用程序；
   6. 性能监控和告警。

**掌握必要的性能优化工具**：下面是 Brendan Gregg 制作的 Linux 性能优化工具图谱，通过这个图可以知道在 Linux 不同子系统出现性能问题后，应该用什么样的工具来观测和分析：

![Brendan Gregg](images/lpo01-all-tools.png "http://www.brendangregg.com/Perf/linux_perf_tools_full.png")

建立性能优化全局观：**性能分析和优化所包含的知识**：

![lpo01-all-skills](images/lpo01-all-skills.png)

**学习目标**：建立整体系统性能的全局观

1. 理解最基本的几个系统知识原理——懂得原理才能有的放矢。
2. 掌握必要的性能优化工具——选对工具才能事半功倍，一个正确的选择胜过千百次的努力。
3. 通过实际的场景演练，贯穿不同的组件——不要停留在在理论，实践才能出真知，经验都是通过无数次实战积累出来的。

>性能优化不只是性能优化工具的学习，而是能够理解其背后的原理。

**高效学习**：

1. 技巧一：不要贪图掌握所有细节。在了解到性能问题对应的系统相关原理后，重点放到如何观察和运用这些原理上，比如：
   1. 有哪些指标可以衡量性能？
   2. 使用什么样的性能工具来观察指标？
   3. 导致这些指标变化的因素等。
2. 边学边实践，通过大量的案例演习掌握 Linux 性能的分析和优化。
3. 勤思考，多反思，善总结，多问为什么。

---

## 2 基础篇：系统变慢——平均负载

### 2.1 什么是平均负载

当系统变慢时，我们通常会使用 `uptime` 和 `top` 命令来了解负载情况。

```shell
# 运行 uptime
uptime
# 结果
15:17:58 up 44 min,  1 user,  load average: 0.00, 0.02, 0.02
```

输出结果说明：

- `15:17:58` 当前时间
- `up 44 min` 系统运行时间
- `1 user` 正在登录用户数
- `load average: 0.00, 0.02, 0.02` 过去 1 分钟、5 分钟、15 分钟的平均负载（LoadAverage）。

**平均负载概念**：指单位时间内，系统处于`可运行状态`和`不可中断状态`的平均进程数，也就是平均活跃进程数。与 CPU 使用率并没有直接关系。

- 可运行状态：正在使用 CPU 或者正在等待 CPU 的进程，用 ps 命令看到的，处于 R 状态（Running 或 Runnable）的进程。
- 不可中断状态：正处于内核态关键流程中的进程，并且这些流程是不可打断的，比如等待硬件设备的 I/O 响应，用 ps 命令看到的，处于 D 状态（Uninterruptible Sleep，也称为 Disk Sleep）的进程。
  - 原因：`不可中断状态实际上是系统对进程和硬件设备的一种保护机制`
  - 距离：`当一个进程向磁盘读写数据时，为了保证数据的一致性，在得到磁盘回复前，它是不能被其他进程或者中断打断的，否自就容易出现磁盘数据与进程数据不一致的问题。`

**平均负载解读**：

- 简单理解：平均活跃进程数。
- 直观理解：单位时间内的活跃进程数。
- 实质上：活跃进程数的指数衰减平均值，简单理解为`活跃进程数的平均值`。

**平均负载指数解读**：要根据 CPU 的核数来解读平均负载数（这里的 CPU 的核数是指逻辑核数），比如当平局负载数为 1 时：

1. 在只有 2 个 CPU 的系统上，意味着所有的 CPU 都刚好被完全占用。
2. 在 4 个 CPU 的系统上，意味着 CPU 有 50% 的空闲。
3. 在只有 1 个 CPU 的系统中，则意味着有一半的进程竞争不到 CPU。

### 2.2 合理的平均负载数

最理想的情况：平均负载是等于 CPU 个数。太高了表示有进程获取不到 CPU 资源，太低了表示 CPU 利用率不高。

**获取CPU 逻辑核数**：

1. `grep 'model name' /proc/cpuinfo | wc -l`
2. top 命令

**系统负载趋势**：平均负载数的三个值都需要关注，以此来判断系统负载变化趋势，从而让我们能更全面、更立体地理解目前的负载状况。

1. 如果三个值相同或者差距不大，表示系统负载平稳。
2. 但如果 1 分钟的值远小于 15 分钟的值，就说明系统最近 1 分钟的负载在减少，而过去15 分钟内却有很大的负载。
3. 如果 1 分钟的值远大于 15 分钟的值，就说明最近 1 分钟的负载在增加，这种增加有可能只是临时性的，也有可能还会持续增加下去，所以就需要持续观察。

**实际生产环境中，如何监控平均负载数**：

1. 当平均负载高于 CPU 数量 70% 的时候，你就应该分析排查负载高的问题了。一旦负载过高，就可能导致进程响应变慢，进而影响服务的正常功能。
2. 最佳做法：把系统的平均负载监控起来，然后根据更多的历史数据，判断负载的变化趋势。当发现负载有明显升高趋势时，比如说负载翻倍了，再去做分析和调查。

### 2.3 平均负载数不等同于 CPU 利用率

原因：平均负载数统计的不仅包括了正在使用 CPU 的进程，还包括等待 CPU 和等待I/O 的进程。

1. CPU 密集型进程，使用大量 CPU 会导致平均负载升高，此时这两者是一致的。
2. I/O 密集型进程，等待 I/O 也会导致平均负载升高，但 CPU 使用率不一定很高。
3. 大量等待 CPU 的进程调度也会导致平均负载升高，此时的 CPU 使用率也会比较高。

### 2.4 案例分析

准备工作：

1. 机器配置：2 CPU，8GB 内存。
2. 预先安装 stress 和 sysstat 包
   1. stress 是一个 Linux 系统压力测试工具
   2. sysstat 包含了常用的 Linux 性能工具，用来监控和分析系统的性能。比如：
      1. `mpstat`：多核 CPU 性能分析工具，用来实时查看每个 CPU 的性能指标，以及所有 CPU 的平均指标。
      2. `pidstat`：进程性能分析工具，用来实时查看进程的 CPU、内存、I/O 以及上下文切换等性能指标。
3. 记录压测前的 `uptime` 数据。

#### CPU 密集型

1 记录压测前的 `uptime` 数据。

```shell
uptime

# 结果
16:47:19 up  2:14,  3 users,  load average: 0.22, 0.12, 0.15
```

2 在第一个终端运行 stress 命令，模拟一个 CPU 使用率 100% 的场景。

```shell
stress --cpu 1 --timeout 600
```

3 在第二个终端运行 uptime 查看平均负载的变化情况。

```shell
# `-d` 参数表示高亮显示变化的区域。
watch -d uptime

# 结果，经过一段时间，平均负载数接近 1
16:49:14 up  2:16,  3 users,  load average: 0.91, 0.42, 0.26
```

4 在第三个终端运行 mpstat 查看 CPU 使用率的变化情况。

```shell
# -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据
mpstat -P ALL 5

# 如果有一个进程的 CPU 使用率为很高，但它的 iowait 很低。这说明，平均负载的升高正是由于 CPU 使用率为太高 。
```

5 pidstat 来查询哪个进程导致了 CPU 使用率为 100%。

```shell
# 间隔 5 秒后输出一组数据
pidstat -u 5 1
```

#### IO 密集型

1 记录压测前的 `uptime` 数据。

```shell
uptime
```

2 在第一个终端运行 stress 命令，模拟 I/O 压力，即不停地执行 sync。

```shell
stress -i 1 --timeout 600
```

>stress 模拟 io 密集型任务原理：stress使用的是 `sync()` 系统调用，它的作用是刷新缓冲区内存到磁盘中。对于新安装的虚拟机，缓冲区可能比较小，无法产生大的 IO 压力，这样大部分就都是系统调用的消耗了。所以，你会看到只有系统 CPU 使用率升高。解决方法是使用 stress 的下一代 `stress-ng`，它支持更丰富的选项，比如 `stress-ng -i 1 --hdd 1 --timeout 600`（--hdd表示读写临时文件）。

3 在第二个终端运行 uptime 查看平均负载的变化情况。

```shell
# `-d` 参数表示高亮显示变化的区域。
watch -d uptime

# 经过一段时间，可以发现平均负载数会升高到接近 1
```

4 在第三个终端运行 mpstat 查看 CPU 使用率的变化情况。

```shell
# -P ALL 表示监控所有 CPU，后面数字 5 表示间隔 5 秒后输出一组数据，数字 20 表示观察 20 次。
mpstat -P ALL 5 20

# 分析结果：如果有一个进程的 CPU 使用率较高，而且它的 iowait 也很高。这说明，很有可能平均负载的升高是由于 iowait 的升高引起的。
```

5 pidstat 来查询哪个进程的 io_wait 高。

```shell
# 间隔 5 秒后输出一组数据
pidstat -u 5 1

# 或者直接查看 io 情况
pidstat -d
```

#### 大量进程的场景

1 记录压测前的 `uptime` 数据。

```shell
uptime
```

2 在第一个终端运行 stress 命令，模拟的是 8 个进程。

```shell
stress -c 8 --timeout 600
```

3 在第二个终端运行 uptime 查看平均负载的变化情况。

```shell
# `-d` 参数表示高亮显示变化的区域。
watch -d uptime

# 经过一段时间，可以发现，由于系统中的 8 个进程明显比 CPU 核数要多得多，因而，系统的 CPU 处于严重过载状态
16:54:23 up  2:21,  3 users,  load average: 4.82, 1.53, 0.67
```

4 在第三个终端运行 pidstat 来看一下进程的情况

```shell
# 间隔 5 秒后输出一组数据
pidstat -u 5 1

# 分析结果：8 个进程在争抢 CPU，每个进程等待 CPU 的时间（也就是 %wait 列）会变得很高。这些超出 CPU 计算能力的进程，最终导致 CPU 过载。
```

>如果 pidstat 输出中没有 %wait 项，是因为 CentOS 默认的 sysstat 稍微有点老，源码或者 RPM 升级到 11.5.5 版本以后就可以看到了。而 Ubuntu 的包一般都比较新，没有这个问题。

### 2.5 扩展学习

- 掌握 uptime 和 top 命令使用与分析。
  - [了解你服务器的心情——top命令详解](https://www.jianshu.com/p/aae6ee900d2e)
  - [top命令详解](https://www.jianshu.com/p/078ed7895b0f)
- 掌握 stress 或 [stress-ng](https://kernel.ubuntu.com/~cking/stress-ng/) 工具的使用。
  - [Linux 压力测试软件 Stress 使用指南](https://www.hi-linux.com/posts/59095.html)
  - [压力测试神器stress-ng](https://cloud.tencent.com/developer/article/1513544)
  - 这些工具主要用于模拟系统过载的情况，可用于验证我们的系统过载预警机制是否有效。
- 掌握 sysstat 工具的使用，掌握 mpstat 和 pidstart 命令的使用。
  - [sysstat github](https://github.com/sysstat/sysstat)
  - [sysstat性能监控工具包中20个实用命令](https://linux.cn/article-4028-1.html)
  - [mpstat 使用介绍和输出参数详解](https://wsgzao.github.io/post/mpstat/)
  - [Linux pidstat命令详解](https://www.jellythink.com/archives/444)

其分析法方案：

1. atop 命令
2. htop 命令
3. 一些公司的服务器安全级别较高，无法安装 sysstat 工具，此时可使用 top、ps、lsof 命令分析。

扩展阅读：[Linux Load Averages: Solving the Mystery](http://www.brendangregg.com/blog/2017-08-08/linux-load-averages.html)
